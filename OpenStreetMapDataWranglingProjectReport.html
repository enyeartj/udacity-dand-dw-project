<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"><style type="text/css">.lst-kix_run0dp3fihxa-4>li:before{content:"\0025cb  "}ul.lst-kix_run0dp3fihxa-8{list-style-type:none}ul.lst-kix_run0dp3fihxa-7{list-style-type:none}.lst-kix_run0dp3fihxa-3>li:before{content:"\0025cf  "}.lst-kix_run0dp3fihxa-5>li:before{content:"\0025a0  "}ul.lst-kix_run0dp3fihxa-6{list-style-type:none}ul.lst-kix_run0dp3fihxa-5{list-style-type:none}.lst-kix_run0dp3fihxa-2>li:before{content:"\0025a0  "}.lst-kix_run0dp3fihxa-6>li:before{content:"\0025cf  "}.lst-kix_run0dp3fihxa-0>li:before{content:"\0025cf  "}.lst-kix_run0dp3fihxa-8>li:before{content:"\0025a0  "}.lst-kix_run0dp3fihxa-1>li:before{content:"\0025cb  "}.lst-kix_run0dp3fihxa-7>li:before{content:"\0025cb  "}ul.lst-kix_run0dp3fihxa-0{list-style-type:none}ul.lst-kix_run0dp3fihxa-4{list-style-type:none}ul.lst-kix_run0dp3fihxa-3{list-style-type:none}ul.lst-kix_run0dp3fihxa-2{list-style-type:none}ul.lst-kix_run0dp3fihxa-1{list-style-type:none}ol{margin:0;padding:0}table td,table th{padding:0}.c0{margin-left:36pt;orphans:2;widows:2}.c2{page-break-after:avoid;orphans:2;widows:2}.c10{background-color:#ffffff;max-width:468pt;padding:72pt 72pt 72pt 72pt}.c6{color:#1155cc;text-decoration:underline}.c3{orphans:2;widows:2}.c8{padding:0;margin:0}.c4{color:inherit;text-decoration:inherit}.c7{height:11pt}.c9{color:#e69138}.c1{color:#ff0000}.c5{padding-left:0pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}</style></head><body class="c10"><p class="c2 title" id="h.rqnggnqx0j28"><span>OpenStreetMap Data Wrangling Project</span></p><p class="c2 title" id="h.uy1y0699260q"><span>Using MongoDB</span></p><p class="c2 subtitle" id="h.e1psztu67uy6"><span>John Enyeart</span></p><p class="c3"><span class="c9">Map Area: Las Vegas, Nevada</span></p><p class="c3"><span class="c6"><a class="c4" href="https://www.google.com/url?q=https://www.openstreetmap.org/relation/170117&amp;sa=D&amp;ust=1457456809650000&amp;usg=AFQjCNHgYaWBH0LdCnAMm687tmvheRkA-g">https://www.openstreetmap.org/relation/170117</a></span></p><p class="c3"><span class="c6"><a class="c4" href="https://www.google.com/url?q=http://metro.teczno.com/%23las-vegas&amp;sa=D&amp;ust=1457456809652000&amp;usg=AFQjCNHDewlx2cF6ccZXq-rWrhzo9ocrug">http://metro.teczno.com/#las-vegas</a></span></p><p class="c3 c7"><span></span></p><h1 class="c2" id="h.xc7vj9qgwy4w"><span>Data Audit</span></h1><p class="c3"><span>Before cleaning and importing the data into MongoDB, I ran an audit on the OpenStreetMap XML file downloaded from the metro extracts site. In the audit, I gathered some general information and checked street names and zip codes in the data so that I would know what kind of cleanup I would need to do.</span></p><p class="c3 c7"><span></span></p><p class="c3"><span>The audit included a count of all of the top-level tags (nodes, ways, relations, etc.) and a listing of unique user IDs. These can be seen in the Data Overview section below. Additionally, I made a count of which keys were all lowercase letters (this indicates there are no problems with the key), which had a colon (this indicates that the key has &ldquo;sub keys&rdquo; which are separated by colons and will need special treatment), which had problem characters, and which didn&rsquo;t fit anything else (these have capital letters, numbers and keys with more than one colon):</span></p><p class="c0"><span class="c1">&gt;&gt;&gt;</span><span>&nbsp;pprint(keys)</span></p><p class="c0"><span>{&#39;lower&#39;: 273809, &#39;lower_colon&#39;: 262977, &#39;other&#39;: 8227, &#39;problemchars&#39;: 0}</span></p><p class="c3 c7"><span></span></p><p class="c3"><span>Next, I checked for abbreviated and unexpected street types. Most of what came up were just abbreviations, but there were a few cases that I needed to double check. One was a street called &ldquo;Via Alicante&rdquo;. I double-checked with Google Maps and found that this street has no &ldquo;street type&rdquo; in its name--it isn&rsquo;t &ldquo;Via Alicante Road&rdquo; or &ldquo;Via Alicante Street&rdquo;, for example, but just &ldquo;Via Alicante&rdquo;. There were also a couple of well known streets that came up without the proper street types. &ldquo;1610 East Tropicana&rdquo; would need to be changed to &ldquo;1610 East Tropicana Avenue&rdquo;, for example.</span></p><p class="c3 c7"><span></span></p><p class="c3"><span>Finally, I checked all the zip codes in the data. All of them started with &ldquo;89&rdquo; as is expected for Las Vegas, but a few were listed as &ldquo;NV 89123&rdquo; or &ldquo;Nevada 89123&rdquo;, for example, so I made a note to fix those in the next stage of the project. There was also one instance of a unicode string that came up as u&rsquo;89123\u200e&rsquo; which would need to be changed to &ldquo;89123&rdquo;.</span></p><p class="c3 c7"><span></span></p><p class="c3"><span>With the audit completed, I was able to move on to cleaning the data, converting it to JSON format, and importing it into MongoDB.</span></p><h1 class="c2" id="h.5yjtj69nfl2i"><span>Data Cleaning</span></h1><p class="c3"><span>In order to clean the data, I processed all nodes and ways to do the following:</span></p><ul class="c8 lst-kix_run0dp3fihxa-0 start"><li class="c0 c5"><span>Removed all punctuation from street names and unabbreviated any abbreviations.</span></li><li class="c0 c5"><span>Fixed zip codes to conform to the format of either 89XXX or 89XXX-XXXX.</span></li><li class="c0 c5"><span>Assembled the data, putting sub tags into a dictionary associated with their base tag.</span></li><li class="c0 c5"><span>Left out any tags with more than one sub tag or with problem characters.</span></li><li class="c0 c5"><span>Put latitude and longitude (if available) as floating point numbers (rather than strings) into an appropriate list.</span></li><li class="c0 c5"><span>Set aside a dictionary of metadata (creation date, username, timestamp, etc.) for each node or way.</span></li><li class="c0 c5"><span>Set a side of all node references for each way.</span></li></ul><p class="c3 c7"><span></span></p><h1 class="c2" id="h.1o4583dptzm"><span>Data Overview</span></h1><h2 class="c2" id="h.yggdg7h7pz6"><span>Size of Files</span></h2><p class="c0"><span>las-vegas_nevada.osm :&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;180,309 KB</span></p><p class="c0"><span>las-vegas_nevada.osm.json :&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;203,080 KB</span></p><h2 class="c2" id="h.m4ip4a43d3ib"><span>Number of Documents</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt;</span><span>&nbsp;db.las_vegas.find().count()</span></p><p class="c0"><span>916706</span></p><h2 class="c2" id="h.sf40qrtwv8jb"><span>Number of Nodes</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>db.las_vegas.find({&quot;type&quot;:&quot;node&quot;}).count()</span></p><p class="c0"><span>824219</span></p><h2 class="c2" id="h.v6rlro94ict6"><span>Number of Ways</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>db.las_vegas.find({&quot;type&quot;:&quot;way&quot;}).count()</span></p><p class="c0"><span>92487</span></p><h2 class="c2" id="h.yqdk8d46lkp5"><span>Number of Unique Users</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>len(db.las_vegas.distinct(&quot;created.user&quot;))</span></p><p class="c0"><span>772</span></p><h2 class="c2" id="h.u26xs32z50q2"><span>Top 10 Zip Codes</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>db.las_vegas.aggregate([</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$match&quot; : { &quot;address.postcode&quot; : { &quot;$exists&quot; : 1 } } },</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$group&quot; : { &quot;_id&quot; : &quot;$address.postcode&quot;,</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;count&quot; : { &quot;$sum&quot; : 1 } } },</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$sort&quot; : { &quot;count&quot; : -1 } },</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$limit&quot; : 10 }</span></p><p class="c0"><span>&nbsp; &nbsp; ])</span></p><p class="c0"><span>[{u&#39;_id&#39;: u&#39;89109&#39;, u&#39;count&#39;: 56},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89122&#39;, u&#39;count&#39;: 51},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89015&#39;, u&#39;count&#39;: 37},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89101&#39;, u&#39;count&#39;: 35},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89005&#39;, u&#39;count&#39;: 28},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89119&#39;, u&#39;count&#39;: 26},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89121&#39;, u&#39;count&#39;: 22},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89142&#39;, u&#39;count&#39;: 21},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89118&#39;, u&#39;count&#39;: 19},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;89002&#39;, u&#39;count&#39;: 16}]</span></p><h2 class="c2" id="h.6oems82tq4u2"><span>Top 10 Restaurants</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>db.las_vegas.aggregate([</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$match&quot; : { &quot;amenity&quot; : &quot;restaurant&quot; } },</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$group&quot; : { &quot;_id&quot; : &quot;$name&quot;,</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&quot;count&quot; : { &quot;$sum&quot; : 1 } } },</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$sort&quot; : { &quot;count&quot; : -1 } },</span></p><p class="c0"><span>&nbsp; &nbsp; &nbsp; &nbsp; { &quot;$limit&quot; : 10 }</span></p><p class="c0"><span>&nbsp; &nbsp; ])</span></p><p class="c0"><span>[{u&#39;_id&#39;: None, u&#39;count&#39;: 18},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&quot;Denny&#39;s&quot;, u&#39;count&#39;: 7},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;Pizza Hut&#39;, u&#39;count&#39;: 5},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;IHOP&#39;, u&#39;count&#39;: 4},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;Buffet@Asia&#39;, u&#39;count&#39;: 3},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;Olive Garden&#39;, u&#39;count&#39;: 3},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&quot;Roberto&#39;s Taco Shop&quot;, u&#39;count&#39;: 3},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&quot;Applebee&#39;s&quot;, u&#39;count&#39;: 3},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;Rivas Mexican Grill&#39;, u&#39;count&#39;: 2},</span></p><p class="c0"><span>&nbsp;{u&#39;_id&#39;: u&#39;Blueberry Hill Family Restaurants&#39;, u&#39;count&#39;: 2}]</span></p><h2 class="c2" id="h.t0pm5lddgumu"><span>Restaurants Near Ranger Station</span></h2><p class="c0"><span class="c1">&gt;&gt;&gt;</span><span>&nbsp;db.las_vegas.ensure_index([(&quot;pos&quot;, GEO2D)])</span></p><p class="c0"><span class="c1">&gt;&gt;&gt;</span><span>&nbsp;loc = db.las_vegas.find_one({ &quot;amenity&quot; : &quot;ranger_station&quot; })[&#39;pos&#39;]</span></p><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>result = db.las_vegas.find({&quot;pos&quot; : {&quot;$near&quot; : loc}, &quot;amenity&quot; : &quot;restaurant&quot;, &quot;name&quot; : { &quot;$exists&quot; : 1 } })</span></p><p class="c0"><span class="c1">&gt;&gt;&gt; </span><span>for i in range(10):</span></p><p class="c0"><span class="c1">... </span><span>&nbsp; &nbsp; pprint(result.next()[&#39;name&#39;])</span></p><p class="c0"><span class="c1">... </span></p><p class="c0"><span>u&#39;Harbor House Cafe&#39;</span></p><p class="c0"><span>u&quot;Evan&#39;s Old Town Grille&quot;</span></p><p class="c0"><span>u&#39;Scratch House Restaurant&#39;</span></p><p class="c0"><span>u&#39;Boulder Dam Hotel Restaurant&#39;</span></p><p class="c0"><span>u&#39;Boulder Dam Brewing Company&#39;</span></p><p class="c0"><span>u&quot;Milo&#39;s Cellar&quot;</span></p><p class="c0"><span>u&quot;Jack&#39;s Place&quot;</span></p><p class="c0"><span>u&quot;Tony&#39;s Pizza&quot;</span></p><p class="c0"><span>u&quot;Tony&#39;d Pizza&quot;</span></p><p class="c0"><span>u&quot;Mel&#39;s Diner&quot;</span></p><h1 class="c2" id="h.1ds73ekpwj3a"><span>Other Ideas About the Dataset</span></h1><p class="c3"><span>In generating the statistics above, I saw that the top &ldquo;restaurant&rdquo; of the top 10 query was &ldquo;None&rdquo;. This is an example of where the dataset could be improved either by researching and inputting the name for restaurants and other amenities without a name field, or, until that information is available, removing those entries from the dataset.</span></p><p class="c3 c7"><span></span></p><p class="c3"><span>Additionally, it would be helpful if more field values were converted to data types other than strings. For example, I thought it would be interesting to make a histogram of dates corresponding to when each node and way were created by using the data in the timestamp field. However, that field was in a string format as opposed to something more workable like a datetime object or a list of integers corresponding to year, month, day. By converting more fields to workable data types, analysis would be much easier. There could be some problems with this conversion, however. For example, when converting timestamps to a datetime object, there would first need to be an audit to make sure the timestamps all conform to the same standard. This could be performed by first observing a few example timestamps, working out what the pattern (supposedly) is, and then creating a regular expression to search timestamp strings and make sure they adhere to the pattern. My guess is that timestamp information is a value input by a computer whenever a user adds to the OpenStreetMap data, so it is likely to be uniform and therefore easier to process. Another problem may be that storing datetime objects could increase memory or disk usage. So if that became an issue, it may be beneficial to split the timestamp up into three integer values for year, month, and day, for example.</span></p><p class="c3 c7"><span></span></p><p class="c3"><span>Another interesting idea would be to list the 10 closest amenities for each node, much how most ways have &ldquo;node references&rdquo;. This could be performed with geospatial indexing using the latitude and longitude data already collected. This could potentially take a long time to complete, however, because for each node, a $near query would have to be performed, and then a calculation of the distance between the node and the query results would have to be performed in order to find which amenities are the closest. Once the calculations are done and the data is input into the database, it would save time over having to do such a query on demand. Once again, this also produces the problem of each data point taking up more disk space, but if it is implemented by simply including a list of 10 node references, that may not be a problem--especially if the speed of having that information precalculated is more valuable than the cost of extra disk space.</span></p></body></html>